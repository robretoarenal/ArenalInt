{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5838ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66393be",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc21ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp = pd.read_table('Data/yelp_labelled.txt')\n",
    "df_imdb = pd.read_table('Data/imdb_labelled.txt')\n",
    "df_amz = pd.read_table('Data/amazon_cells_labelled.txt')\n",
    "# Concatenate our Datasets\n",
    "frames = [df_yelp,df_imdb,df_amz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c4a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in frames: \n",
    "    column.columns = [\"Message\",\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0541c532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Yelp</th>\n",
       "      <th>0</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Message  Target\n",
       "Yelp 0                                 Crust is not good.       0\n",
       "     1          Not tasty and the texture was just nasty.       0\n",
       "     2  Stopped by during the late May bank holiday of...       1\n",
       "     3  The selection on the menu was great and so wer...       1\n",
       "     4     Now I am getting angry and I want my damn pho.       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign a Key to Make it Easier\n",
    "keys = ['Yelp','IMDB','Amazon']\n",
    "# Merge or Concat our Datasets\n",
    "df = pd.concat(frames,keys=keys)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5516b9",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b83680db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "#parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4137fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(doc):\n",
    "    return [token.lemma_ for token in doc if not\n",
    "           (token.is_punct or token.is_space or token.lower_ in STOP_WORDS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00607eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our tokenizer function. This function will lemmatize, remove stop words, remove punctuations and remove noun? proper noun?\n",
    "def spacy_tokenizer(doc):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    #mytokens = parser(sentence)\n",
    "    tokens = nlp(doc)\n",
    "    #print(tokens)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    #tokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    tokens = [word.lemma_.lower() for word in tokens]\n",
    "    #print(tokens)\n",
    "    \n",
    "    # Removing stop words and punctuations\n",
    "    tokens = [ word for word in tokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Hey my name is Roberto and I am the best!'\n",
    "doc = nlp(sent)\n",
    "lemmatize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc221200",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokenizer(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7d150f",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c91c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin \n",
    "\n",
    "# This function will clean the text\n",
    "def clean_text(text):     \n",
    "    return text.strip().lower()\n",
    "    \n",
    "#Custom transformer using Python standard library (you could use spacy as well)\n",
    "class predictors(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a839e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# We create our bag of words (bow) using our tokenizer and defining an ngram range\n",
    "bow = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1)) \n",
    "# Using Tfidf\n",
    "tfvectorizer = TfidfVectorizer(tokenizer = spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3d727cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and Labels\n",
    "X = df['Message']\n",
    "ylabels = df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05adf364",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9556f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = tfvectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece05da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9138b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', tfvectorizer)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d053ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"I do enjoy my job\",\n",
    " \"What a poor product!,I will have to get a new one\",\n",
    " \"I feel amazing!\",\n",
    " \"This class sucks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab6cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pipe.fit_transform(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac31fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06f4b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot confusion matrix.\n",
    "def cmplot(cm):\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');\n",
    "    ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    ax.xaxis.set_ticklabels(['0', '1']); \n",
    "    ax.yaxis.set_ticklabels(['0', '1']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a90ff82",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Suporting Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c31d96",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# SVC classifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "classifier_SVC = LinearSVC(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102bc00b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create the  pipeline to clean, tokenize, vectorize, and classify \n",
    "pipe1_svc = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow),\n",
    "                 ('classifier', classifier_SVC)], verbose=True)\n",
    "\n",
    "pipe2_svc = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', tfvectorizer),\n",
    "                 ('classifier', classifier_SVC)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e0e7f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipe1_svc.fit(X_train,y_train)\n",
    "pipe2_svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dfe2b5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "svc1_prediction = pipe1_svc.predict(X_test)\n",
    "svc2_prediction = pipe2_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271e1532",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, svc1_prediction)\n",
    "#TN FP\n",
    "#FN TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb10cbe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cm=metrics.confusion_matrix(y_test, svc1_prediction)\n",
    "cmplot(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ce9d76",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, svc1_prediction))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, svc1_prediction))#Positive predictive value\n",
    "print(\"Recall:\",metrics.recall_score(y_test, svc1_prediction))#Sensitivity, hit rate, true positive rate\n",
    "print(\"Specificity:\", metrics.recall_score(y_test, svc1_prediction,pos_label=0))#Specificity, true negative rate\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test,svc1_prediction))#measure of preciseness and robustness of model. 2TP/(2TP+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf46ca43",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cm=metrics.confusion_matrix(y_test, svc2_prediction)\n",
    "cmplot(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1def63",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, svc2_prediction))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, svc2_prediction))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, svc2_prediction))\n",
    "print(\"Specificity:\", metrics.recall_score(y_test, svc2_prediction,pos_label=0))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test,svc2_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6283fe",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2228c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier_LG = LogisticRegression(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d066acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the  pipeline to clean, tokenize, vectorize, and classify \n",
    "pipe1_LG = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow),\n",
    "                 ('classifier', classifier_LG)], verbose=True)\n",
    "\n",
    "pipe2_LG = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', tfvectorizer),\n",
    "                 ('classifier', classifier_LG)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b53540e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 3) Processing cleaner, total=   0.0s\n",
      "[Pipeline] ........ (step 2 of 3) Processing vectorizer, total=   8.7s\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =         3271     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.33154D+03    |proj g|=  6.15000D+01\n",
      "\n",
      "At iterate   50    f=  6.80088D+02    |proj g|=  9.01651D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      " 3271     58     61      1     0     0   6.101D-03   6.801D+02\n",
      "  F =   680.08805755596006     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 3) Processing cleaner, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 3) Processing vectorizer, total=  10.7s\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =         3271     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.33154D+03    |proj g|=  2.13949D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      " 3271     20     24      1     0     0   1.211D-03   9.672D+02\n",
      "  F =   967.22004087261587     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cleaner', <__main__.predictors object at 0x7f202f4da1d0>),\n",
       "                ('vectorizer',\n",
       "                 TfidfVectorizer(tokenizer=<function spacy_tokenizer at 0x7f2030c72a70>)),\n",
       "                ('classifier', LogisticRegression(verbose=True))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1_LG.fit(X_train,y_train)\n",
    "pipe2_LG.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b216bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plg1_prediction = pipe1_LG.predict(X_test)\n",
    "plg2_prediction = pipe2_LG.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff686d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, plg1_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef45596",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=metrics.confusion_matrix(y_test, plg1_prediction)\n",
    "cmplot(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7445e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, plg1_prediction))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, plg1_prediction))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, plg1_prediction))\n",
    "print(\"Specificity:\", metrics.recall_score(y_test, plg1_prediction,pos_label=0))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test,plg1_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba6ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test, plg1_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, plg2_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96db7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=metrics.confusion_matrix(y_test, plg2_prediction)\n",
    "cmplot(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aad399",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, plg2_prediction))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, plg2_prediction))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, plg2_prediction))\n",
    "print(\"Specificity:\", metrics.recall_score(y_test, plg2_prediction,pos_label=0))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test,plg2_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_curve(y_test, plg2_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac40fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test, plg2_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779fca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(pipe2_LG, X, ylabels,cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e27834",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edd4e74",
   "metadata": {},
   "source": [
    "## MultiLayer Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8413d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi layer perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier_MLP =  MLPClassifier(max_iter=400, hidden_layer_sizes=(100,2), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e38f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the  pipeline to clean, tokenize, vectorize, and classify \n",
    "pipe1_mlp = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow),\n",
    "                 ('classifier', classifier_MLP)], verbose=True)\n",
    "\n",
    "pipe2_mlp = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', tfvectorizer),\n",
    "                 ('classifier', classifier_MLP)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d64ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1_mlp.fit(X_train,y_train)\n",
    "pipe2_mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c13273",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp1_prediction = pipe1_mlp.predict(X_test)\n",
    "mlp2_prediction = pipe2_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512bd00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, mlp1_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc81d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=metrics.confusion_matrix(y_test, mlp1_prediction)\n",
    "cmplot(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4519051",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, mlp1_prediction))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, mlp1_prediction))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, mlp1_prediction))\n",
    "print(\"Specificity:\", metrics.recall_score(y_test, mlp1_prediction,pos_label=0))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test,mlp1_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e79411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, mlp2_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=metrics.confusion_matrix(y_test, mlp2_prediction)\n",
    "cmplot(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4307855",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, mlp2_prediction))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, mlp2_prediction))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, mlp2_prediction))\n",
    "print(\"Specificity:\", metrics.recall_score(y_test, mlp2_prediction,pos_label=0))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test,mlp2_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e798fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"I do enjoy my job\",\n",
    " \"What a poor product!,I will have to get a new one\",\n",
    " \"I feel amazing!\",\n",
    " \"This class sucks\"]\n",
    "\n",
    "#pipe2_mlp.predict(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31674b",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40680a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f85425ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/logreg_tfidf2.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe2_LG, \"model/logreg_tfidf2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_loaded = joblib.load(\"model/logreg_tfidf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e30b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_loaded.predict(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a595aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipe2, \"mlp_tfidf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcbef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_loaded = joblib.load(\"mlp_tfidf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a6e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_loaded.predict(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faca7a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
